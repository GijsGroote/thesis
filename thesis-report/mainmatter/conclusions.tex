\chapter{Conclusions}%
\label{chap:conclusion}
This thesis aims to create a robot framework that can; learning object dynamics, solve \ac{NAMO} problems and perform nonprehensile pushing. The overwhelming research in these individual topics stand is contrast to the sparse number of recent papers that combine these three aforementioned topics. This absence of research can be motivated by the emerged challenges when combining the three topics such as the uncertainty in planning and the complexity class of the overall problem.\bs

% main research question improved in two aspects
The main research question, that is: \textit{How do learned objects' system models improve global task planning for a robot with nonprehensile push manipulation abilities over time?} is answered in \Cref{chap:results} that presents the results. These results provide evidence for improved task execution with learned objects' system models in two aspects. The first improvement is due to classification of objects, that improves the success rate of generated action sequences. Mainly because, probabilistic action sequences that may involve pushing unmovable objects cannot occur when object classification is present. During task execution the proposed framework gathers experience by storing action feedback after successful or unsuccessful actions. As a result the proposed framework converges toward an best strategy to manipulate objects which is the second improved aspect.\bs

% randomized environment and comparison to state-of-the-art
To obtain unbiased results, drive and pushing tasks have been performed with randomized settings. In that randomized environment, once tasks are solved with action suggestions from the \ac{k-graph}, and once by randomly selecting edge parameterizations. The results indicate that leveraging environmental experience by selecting action suggestions significant improvements are made. These improvements were measured with the \acl{PE} and the search-, execute- and total time to complete a task, such improvements are due to selecting the best available controller and system model combination also named edge parameterization. Two important factors determine convergence toward an optimal selection of controller and system model combination. First the success factor, because it determines which experience of control and system model combination is the best choice to manipulate a specific object. Second, the set of available controllers and system models, because the proposed framework can only converge to the best available controller in the set of available controllers. During testing analytic models were used that cannot model a wide variety of systems accurately. \Cref{table:sota_vs_results_proposed} shows therefore a \xmark/\cmark, concluding that the proposed framework can partly combine the three topics. The analytic models could be replaced by adding a system identification module that is moved to the future work section, if implemented the proposed framework can claim that the three topics can fully be combined.\bs

Research subquestion~\ref{researchsubquestion:does_it_work}, that is: \textit{How to combine learning and planning for push and drive applications?} An answer is given in \Cref{chap:required_background,chap:proposed_planning,chap:h-graph_and_k-graph}. Here it is shown how the proposed framework, that consists of the \acf{h-algorithm}, the \acf{h-graph} and the \acf{k-graph} work together to combine learning and planning with the backward search technique. The curse of dimensionality and an \ac{NP-hard} problem are bypassed by searching only in a single mode of dynamics instead of searching in composite space. \Cref{chap:h-graph_and_k-graph} defines the proposed robot framework, in this chapter the \ac{h-graph} is defined as a graph-based structure that presents how the \ac{h-algorithm} is trying to complete a subtask. Action sequences are generated by starting a search from the desired outcome and searching backward to the current configuration with the backward search technique. Newly gained environmental knowledge is stored in the \ac{k-graph}, which firstly classifies objects as movable or unmovable, and secondly holds information on how they can be best manipulated. The \ac{k-graph} can be filled with newly learned environmental knowledge and can be queried for action suggestions. The chapter shows how learned system knowledge can be leveraged by alternating between searching for an action sequence and executing an action sequence.\bs

Research subquestion~\ref{researchsubquestion:does_it_compare}, that is: \textit{How does the proposed framework compare against the state-of-the-art?} The proposed framework was able to improve upon \citeauthor{wang_affordancebased_2020} proposed method in terms of execution- and total time. Only one state-of-the-art methods was compared whilst five had been selected for comparison. Further comparisons are moved to the future work, if compared conclusions can be drawn on other test metrics such as success rate or number of replanning.\bs

The proposed framework partly combines the three topics, the \ac{NAMO} is tackled by extending an existing path planner that detects blocked paths. The \ac{h-algorithm} then combines the extended path planner with the backward search technique to search for action sequences. Action sequences consists of drive and push actions that improve over time by reviewing actions and storing action review in the \ac{k-graph}. Thereby, nonprehensile pushing, learning and the \ac{NAMO} problem are combined in the proposed framework. Since the proposed framework classifies objects and stores action feedback, it is concluded that the three topics are partly combined. The proposed framework improves upon the state-of-the-art by a significant margin in search- and execution time.\bs
